{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that my entire dataset is only 17,688 entries, fits neatly into a csv file, and runs in a Jupyter Notebook, I'm going to try to write a recommender from scratch using a lecture from Matt Drury.\n",
    "\n",
    "To start, I'm going to need my Utility Matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# first load my data...\n",
    "ratings = pd.read_csv('../data/ratings.csv', delimiter='|', header=None, names=['user_id', 'system_id', 'ratings'])\n",
    "\n",
    "# get highest user_id & highest system_id\n",
    "highest_user_id = ratings.user_id.max()\n",
    "highest_system_id = ratings.system_id.max()\n",
    "\n",
    "# make a sparse matrix...\n",
    "utility_matrix = sparse.lil_matrix((highest_user_id + 1, highest_system_id + 1))\n",
    "# +1 to be able to use actual ids, as opposed to having to make consessions\n",
    "\n",
    "# of course, now I need to fill it with ratings...\n",
    "for _, row in ratings.iterrows():\n",
    "        utility_matrix[row.user_id, row.system_id] = row.ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to find cosine similarities... the following function ws taken from my [Galvanize](https://www.galvanize.com/seattle/data-science) classwork on the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def make_cos_sim_and_neighborhoods(ratings_mat, neighborhood_size):\n",
    "    '''\n",
    "    Accepts a 2 dimensional matrix ratings_mat, and an integer neighborhood_size.\n",
    "    Returns a tuple containing:\n",
    "        - items_cos_sim, an item-item matrix where each element is the\n",
    "        cosine_similarity of the items at the corresponding row and column. This\n",
    "        is a square matrix where the length of each dimension equals the number\n",
    "        of columns in ratings_mat.\n",
    "        - neighborhood, a 2-dimensional matrix where each row is the neighborhood\n",
    "        for that item. The elements are the indices of the n (neighborhood_size)\n",
    "        most similar items. Most similar items are at the end of the row.\n",
    "    '''\n",
    "    items_cos_sim = cosine_similarity(ratings_mat.T)\n",
    "    least_to_most_sim_indexes = np.argsort(items_cos_sim, 1)\n",
    "    neighborhood = least_to_most_sim_indexes[:, -neighborhood_size:]\n",
    "    return items_cos_sim, neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the utility matrix from above and a neighborhood size of 75 for fun...\n",
    "items_cos_sim, neighborhoods = make_cos_sim_and_neighborhoods(utility_matrix, neighborhood_size=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to be able to make predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def pred_one_user(user_id, item_cos_sim, neighborhoods, ratings_mat, timer=False):\n",
    "    '''\n",
    "    Accept user id as arg. Return the predictions for a single user.\n",
    "\n",
    "    Optional argument to specify whether or not timing should be provided\n",
    "    on this operation.\n",
    "    '''\n",
    "    if timer:\n",
    "        start = time.clock()\n",
    "    n_items = ratings_mat.shape[1]  # number of items\n",
    "    items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "    # Just initializing so we have somewhere to put rating preds\n",
    "    output = np.zeros(n_items)\n",
    "    for item_to_rate in xrange(n_items):\n",
    "\n",
    "        relevant_items = np.intersect1d(neighborhoods[item_to_rate],\n",
    "                                        items_rated_by_this_user,\n",
    "                                        assume_unique=True)\n",
    "                                    # assume_unique speeds up intersection op\n",
    "        output[item_to_rate] = ratings_mat[user_id, relevant_items] * \\\n",
    "            item_cos_sim[item_to_rate, relevant_items] / \\\n",
    "            item_cos_sim[item_to_rate, relevant_items].sum()\n",
    "    output = np.nan_to_num(output)  # get rid of nan values...\n",
    "    if timer:\n",
    "        end = time.clock()\n",
    "        print 'output... {:.3f}'.format(end-start)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2437    65232\n",
      "2462    66112\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test the above...\n",
    "user_test = ratings.groupby('user_id').ratings.count().reset_index(name='count')\n",
    "test_user = user_test[user_test['count'] == user_test['count'].max()]['user_id']\n",
    "print test_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.02857636626\n",
      "1 1.03726877441\n",
      "1 1.06797898995\n",
      "1 1.03109590023\n",
      "1 1.09266881413\n",
      "1 1.03368475257\n",
      "1 1.02419317323\n",
      "1 1.02094702972\n",
      "1 1.04861761502\n",
      "3 2.57315861917\n",
      "1 1.02295067111\n",
      "1 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darin\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "preds = pred_one_user(65232, items_cos_sim, neighborhoods, utility_matrix)\n",
    "for system in ratings[ratings['user_id'] == 65232]['system_id']:\n",
    "    rat = int(ratings[(ratings['user_id'] == 65232) & (ratings['system_id'] == system)]['ratings'])\n",
    "    print rat, preds[system]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so not too terrible... but we need to do some sort of validation... and this is an issue.  There are different methods; randomly remove some number of values and check against them, use a time-based model where we train on a certain time period, then look at test/validation as time moves forward, etc.\n",
    "\n",
    "My plan, for better or worse, is to remove about 20% of users, rerun the sims and neighborhoods, then check agianst the hold-out users.  I can create a train_utility_matrix for this, then predict on the standard one using my holdouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# select a hold-out set...\n",
    "user_ids = list(set(ratings['user_id'].tolist()))\n",
    "shuffle(user_ids)  # somewhat shuffled already, but whatever\n",
    "index = int(len(user_ids)*.8)\n",
    "train_users = user_ids[:index]\n",
    "hold_out = user_ids[index:]\n",
    "\n",
    "# now to make a new matrix...\n",
    "train_users.sort()\n",
    "highest_user_id = train_users[-1]\n",
    "train_utility_matrix = sparse.lil_matrix((highest_user_id + 1, highest_system_id + 1))\n",
    "# +1 to be able to use actual ids, as opposed to having to make consessions\n",
    "\n",
    "# of course, now I need to fill it with ratings...\n",
    "for _, row in ratings.iterrows():\n",
    "    if row.user_id in train_users:\n",
    "        train_utility_matrix[row.user_id, row.system_id] = row.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the train utility matrix from above and a neighborhood size of 75 for fun...\n",
    "train_items_cos_sim, train_neighborhoods = make_cos_sim_and_neighborhoods(train_utility_matrix, neighborhood_size=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I have the ratings from my hold_out users in my old Utility_matrix, I can reuse it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darin\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100.00% \n",
      "RMSE = 0.182441491839, Max Error = 5.0\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "n = 0\n",
    "RMSE = 0\n",
    "max_err = 0\n",
    "for i, user in enumerate(hold_out):\n",
    "    # use actual utility matrix to get their ratings... train for the test info\n",
    "    preds = pred_one_user(user, train_items_cos_sim, train_neighborhoods, utility_matrix)\n",
    "    for system in ratings[ratings['user_id'] == user]['system_id']:\n",
    "        rat = int(ratings[(ratings['user_id'] == user) & (ratings['system_id'] == system)]['ratings'])\n",
    "        sub = preds[system] - rat\n",
    "        if abs(sub) >= max_err:\n",
    "            max_err = abs(sub)\n",
    "        RMSE = RMSE + (preds[system] - rat)**2\n",
    "        n += 1\n",
    "    print 'Progress {:.2f}% \\r'.format(100.0*(i + 1)/float(len(hold_out))),\n",
    "RMSE = sqrt(RMSE/n)\n",
    "print \n",
    "print 'RMSE = {}, Max Error = {}'.format(RMSE, max_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is okay, that max error is really high... I'm off by as much as 5 for some users... this is similar to the results I was getting in Spark, though with a better RMSE (guess Spark's method not as good as this method, but likely makes up for it in ability to handle Big Data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so time to use Matrix Factorization.  I'll be using Nonnegative Matrix Factorization (NMF) from [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html). I'm a fan of Nonnegative Matrix Factorization for 2 reasons:\n",
    "1. There are no negative values, which prevents weird results.  Since there is no 'thumbs down' other than not purchasing a product, I don;t want to have negative values spitting out negative results.\n",
    "2. I prefer the US matrix form, since it allows for manipulation with a K matrix... U is u x k, S is k x s, and K is a k x k matrix you can throw in... if K is I (identity) it has absolutly no effect, but you can maipulate results by tossing numbers on the off-diagonals (for example, in a boom recommender, you can find the group that pregnancy books are in, find the group that stillbirth books are in, and have it negativley influence result for pregnancy books if you're interested in stillbirth books, since that seems like a cruel thing to hit customers with)\n",
    "\n",
    "There is an issue however... I won;t be able to use non-users to validate the way I did above; they need to get a vector at the same time as everyone else... so I need to 'knock out' values in my utility_matrix to fit back in later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so time to use Matrix Factorization. I'll be using Non-Negative Matrix Factorization (NMF). I'm a fan of Non-Negative Matrix Factorization for 2 reasons:\n",
    "1. There are no negative values, which prevents weird results. Since there is no 'thumbs down' other than not purchasing a product, I don;t want to have negative values spitting out negative results.\n",
    "2. I prefer the US matrix form, since it allows for manipulation with a K matrix... U is u x k, S is k x s, and K is a k x k matrix you can throw in... if K is I (identity) it has absolutly no effect, but you can maipulate results by tossing numbers on the off-diagonals (for example, in a boom recommender, you can find the group that pregnancy books are in, find the group that stillbirth books are in, and have it negativley influence result for pregnancy books if you're interested in stillbirth books, since that seems like a cruel thing to hit customers with)\n",
    "\n",
    "There is an issue however... I won't be able to use non-users to validate the way I did above; they need to get a vector at the same time as everyone else... so I need to 'knock out' values in my utility_matrix to fit back in later...but that means I need to grab that again, since I'm in a new notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# first load my data...\n",
    "ratings = pd.read_csv('../data/ratings.csv', delimiter='|', header=None, names=['user_id', 'system_id', 'ratings'])\n",
    "\n",
    "# get highest user_id & highest system_id\n",
    "highest_user_id = ratings.user_id.max()\n",
    "highest_system_id = ratings.system_id.max()\n",
    "\n",
    "# make a sparse matrix...\n",
    "utility_matrix = sparse.lil_matrix((highest_user_id + 1, highest_system_id + 1))\n",
    "# +1 to be able to use actual ids, as opposed to having to make consessions\n",
    "\n",
    "# of course, now I need to fill it with ratings...\n",
    "for _, row in ratings.iterrows():\n",
    "        utility_matrix[row.user_id, row.system_id] = row.ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to remove 20% of my data points and call it the *train_utility_matrix*.  Goal is to make a list of tuples of *user_id* and *system_id*, then set the values at those locations to 0 in a copy of the *utility_matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n",
      "1.0 0.0\n",
      "1.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "train_utility_matrix = utility_matrix.copy()\n",
    "utility_dict = utility_matrix.todok(copy=False)\n",
    "lst = utility_dict.keys()\n",
    "shuffle(lst)\n",
    "cut = int(len(lst)*0.8)\n",
    "train = lst[:cut]\n",
    "hold_out = lst[cut:]\n",
    "\n",
    "# now remove hold_out\n",
    "for tup in hold_out:\n",
    "    train_utility_matrix[tup] = 0\n",
    "    \n",
    "for tup in hold_out[:5]:\n",
    "    print utility_matrix[tup], train_utility_matrix[tup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NMF module from [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) does not seem like [a good fit](https://stackoverflow.com/questions/33623144/how-can-i-make-recommendation-model-using-pythons-scikit-learn) as it does not seem to allow much modification of the cost function to account for recommendation systems.  So, I'll need to write my own.\n",
    "Luckily I did build an NMF class as part of my [Galvanize data science course](https://www.galvanize.com/seattle/data-science), so that's floating around my hard drive/github.\n",
    "But, I need to change my cost function to the following cost function (thank you [Matt Drury](https://github.com/madrury)):\n",
    "$$arg: min_{U,V,b^*,b'} \\sum_{i, j \\in \\kappa} (r_{ij} - \\mu - b_i^* - b_j' - u_{i:} \\cdot v_{:j})^2 + \\lambda_1(\\parallel u_{i:}\\parallel^2 + \\parallel v_{:j}\\parallel^2) + \\lambda_2((b_i^*)^2 + (b_j')^2) $$\n",
    "Where $r_{ij}$ is user i's rating of item j, $u_{i:}$ is the way user i interacts with our latent features, $v_{j:}$ is how item j is described in terms of our latent features, $b_i^*$ is how much user i deviates from the overall average, and $b_j'$ is how much item j deviates from the overall average, $\\mu$.  This gives me a rating function of:\n",
    "$$r_{ij} \\approx \\mu + b_i^* + b_j' + u_{i:} \\cdot v_{:j}$$ \n",
    "\n",
    "Of course, I need  least-squares solution in order to do this.  What I have is [numpy.linalg.lstsq()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html).  This minimizes the following function:\n",
    "$$arg: min \\parallel b - a x \\parallel^2  =  min \\parallel R - UV \\parallel^2 = min_{U,V} \\sum_{i, j \\in \\kappa} (r_{ij} - u_{i:} \\cdot v_{:j})^2 $$ \n",
    "What we want is the following, if we make a small assumption: Make a matrix B such that $b_{ij} =  b_i^* + b_j'$.  Now, we can make our function the following (assuming $((b_i^*)^2 + (b_j')^2) \\approx \\parallel b_{ij} \\parallel^2$)\n",
    "$$arg: min \\parallel R - UV \\parallel^2 + \\lambda_1\\parallel U \\parallel^2 + \\lambda_1\\parallel V \\parallel^2 + \\lambda_2\\parallel B \\parallel^2$$\n",
    "\n",
    "Since we can [translate](https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization): $\\parallel b - a x \\parallel^2 + lambda\\parallel x \\parallel^2$ as: `np.linalg.lstsq(a + lamb, b)`, we can simply solve for the various parts in these terms, which gives us: a = U + $\\lambda_1$I and b = R - $\\mu$ + ($\\lambda_2$ - 1)B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "class NMF_recommender(object):\n",
    "    '''\n",
    "    A Non-Negative Matrix Factorization recommender.\n",
    "    Parameters:\n",
    "        k - The number of latent features\n",
    "        max_iter - number of iterations before the Factorization cancels out\n",
    "        thresh - the threshold, how different the cost function needs to be in\n",
    "                 in order to kick out of the iterations.\n",
    "        l1 - lamba_1 in cost function\n",
    "        l2 - lamba_2 in cost function\n",
    "        verbose - set True to print out Cost Function during fitting\n",
    "            \n",
    "    Attributes:\n",
    "        k - number of latent features\n",
    "        iter - max_iter\n",
    "        thresh - threshold paramater\n",
    "        l1 - lamba_1\n",
    "        l2 - lamba_2\n",
    "    '''\n",
    "\n",
    "    def __init__(self, k, max_iter=100, thresh=0.0001, l1=0.1, l2=0.1, verbose=False):\n",
    "        '''\n",
    "        Initializer.  See class for details.\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.thresh = thresh\n",
    "        self.iter = max_iter\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Fit function for the recommender system.\n",
    "        Parameters:\n",
    "            X - the utility-matrix we are trying to fit to\n",
    "\n",
    "        Attributes:\n",
    "            V - utility matrix in array form\n",
    "            nonzero - a numpy array that is 1 where utility matrix is\n",
    "                      nonzero and 0 otherwise\n",
    "            b_star - how much users deviate from average\n",
    "            b_prime - how much items deviate from average\n",
    "            b_matrix - a matrix of b_stari - b_primej for all i,j\n",
    "            cost - the cost function for a recommender\n",
    "            W - User matrix\n",
    "            H - Item Matrix\n",
    "        '''\n",
    "        # turn utility matrix to an arry\n",
    "        self.V = X.toarray()\n",
    "        nonzero = np.where(self.V > 0,1 ,0)\n",
    "        k  = self.k\n",
    "        \n",
    "        # find mu...\n",
    "        self.mu = np.sum(self.V)/np.count_nonzero(self.V)\n",
    "        \n",
    "        # find b_star & b_prime\n",
    "        self.b_star = np.mean(self.V - self.mu*nonzero, axis=1)\n",
    "        self.b_prime = np.mean(self.V - self.mu*nonzero, axis=0)\n",
    "        \n",
    "        # make b_matrix...\n",
    "        # first, get a matrix of b_star as columns\n",
    "        self.b_matrix =  np.column_stack((self.b_star for a in xrange(self.b_prime.shape[0])))\n",
    "        # add to b_prime as rows...\n",
    "        self.b_matrix = self.b_matrix + np.row_stack((self.b_prime for a in xrange(self.b_star.shape[0])))\n",
    "       \n",
    "        \n",
    "        self.W = np.random.random_sample((self.V.shape[0], k))\n",
    "        self.H = np.ones((k, self.V.shape[1]))\n",
    "        if self.verbose:\n",
    "            print 'Getting cost...'\n",
    "        #cost function...\n",
    "        Q = self.V - self.mu - self.b_matrix\n",
    "        self.cost = (np.linalg.norm(Q - self.W.dot(self.H)) + \n",
    "                         self.l1*(np.linalg.norm(self.W) + np.linalg.norm(self.H)) +\n",
    "                         self.l2*(self.b_star.dot(self.b_star) + self.b_prime.dot(self.b_prime)))\n",
    "        if self.verbose:\n",
    "            print 'Cost starts at: {}'.format(self.cost)\n",
    "        n = 0\n",
    "        old_cost = self.cost + 2 * self.thresh\n",
    "        I = np.identity(k)\n",
    "        while (n < self.iter) and (abs(old_cost - self.cost) > self.thresh):\n",
    "            if n % 2 == 0:\n",
    "                self.H = np.linalg.lstsq(self.W + self.l1, Q + self.l2*self.b_matrix)[0]\n",
    "                self.H[self.H < 0] = 0\n",
    "            else:\n",
    "                self.W = np.linalg.lstsq(self.H.T + self.l1, (Q + self.l2*self.b_matrix).T)[0].T\n",
    "                self.W[self.W < 0] = 0\n",
    "            old_cost = self.cost\n",
    "            self.cost = (np.linalg.norm(Q - self.W.dot(self.H)) + \n",
    "                         self.l1*(np.linalg.norm(self.W) + np.linalg.norm(self.H)) +\n",
    "                         self.l2*(self.b_star.dot(self.b_star) + self.b_prime.dot(self.b_prime)))\n",
    "            n +=1\n",
    "            if self.verbose:\n",
    "                print \"Iteration {}: Cost Difference = {}\".format(n, abs(old_cost - self.cost))\n",
    "        return self.W, self.H\n",
    "    \n",
    "    def predict(self):\n",
    "        '''\n",
    "        Get values for items.                \n",
    "        Attributes:\n",
    "            ratings - The returned ratings\n",
    "        '''\n",
    "        self.ratings = self.mu + self.b_matrix + self.W.dot(self.H)\n",
    "        return self.ratings\n",
    "\n",
    "    def predict_cold(self, v):\n",
    "        '''\n",
    "         Fit function for the recommender system.\n",
    "        Parameters:\n",
    "            v - a list of tuples describing how user rated items,\n",
    "                format [(item_1, rating_1), (item_2, rating_2), ..., (item_n, raing_n)]\n",
    "\n",
    "        Attributes:\n",
    "            ratings - The returned ratings for all the included users\n",
    "        '''\n",
    "        # make sure we have ratings\n",
    "        try:\n",
    "            ratings = self.ratings\n",
    "        except:\n",
    "            ratings = self.predict()\n",
    "        pass\n",
    "\n",
    "    def get_rmse(self, X_full):\n",
    "        '''\n",
    "        Assumes a training matrix with missing values was used, checks the values that are in\n",
    "        X_full but not in self.V and calculates the RMSE.\n",
    "        Parameters:\n",
    "            X_full - the utility-matrix that vaules were removed from to get X in our fit\n",
    "\n",
    "        Attributes:\n",
    "            Xf - the full utility matric\n",
    "            rmse - root mean squared error\n",
    "        '''\n",
    "         # make sure we have ratings\n",
    "        ratings = self.predict()\n",
    "        self.Xf = X_full.toarray()\n",
    "        X_1 = np.where(self.Xf > 0, 1, 0)\n",
    "        X_2 = np.where(self.V == 0, 0, 1)\n",
    "        X_check = X_1 - X_2\n",
    "        X_check[X_check <= 0] = 0\n",
    "        self.rmse = sqrt(np.sum((self.Xf[X_check==1] - self.ratings[X_check==1])**2)/float(np.count_nonzero(X_check)))\n",
    "        return self.rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Searching (in an ec2 to allow it to run when I'm not around) gave me the following parameters as 'best':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cost...\n",
      "Cost starts at: 56731.4481707\n",
      "Iteration 1: Cost Difference = 32024.5955138\n",
      "Iteration 2: Cost Difference = 9.86481736393e+15\n",
      "Iteration 3: Cost Difference = 3.15696361028e+15\n",
      "Iteration 4: Cost Difference = 4.54519767464e+15\n",
      "Iteration 5: Cost Difference = 6.51121429751e+14\n",
      "Iteration 6: Cost Difference = 1.69158572179e+16\n",
      "Iteration 7: Cost Difference = 518.537702045\n",
      "Iteration 8: Cost Difference = 66705.6363999\n",
      "Iteration 9: Cost Difference = 20.34088178\n",
      "Iteration 10: Cost Difference = 803257.729809\n",
      "Iteration 11: Cost Difference = 17.2693096879\n",
      "Iteration 12: Cost Difference = 1245384.08952\n",
      "Iteration 13: Cost Difference = 0.073382018134\n",
      "Iteration 14: Cost Difference = 1998013.16445\n",
      "Iteration 15: Cost Difference = 0.0733792455867\n",
      "Iteration 16: Cost Difference = 3247420.36189\n",
      "Iteration 17: Cost Difference = 0.0733777340502\n",
      "Iteration 18: Cost Difference = 5324281.45968\n",
      "Iteration 19: Cost Difference = 0.0733761005104\n",
      "Iteration 20: Cost Difference = 8836582.90385\n",
      "Iteration 21: Cost Difference = 0.0733729079366\n",
      "Iteration 22: Cost Difference = 14911783.2273\n",
      "Iteration 23: Cost Difference = 0.0733655542135\n",
      "Iteration 24: Cost Difference = 25711060.7625\n",
      "Iteration 25: Cost Difference = 0.0733519867063\n",
      "Iteration 26: Cost Difference = 45489446.7576\n",
      "Iteration 27: Cost Difference = 0.0733353793621\n",
      "Iteration 28: Cost Difference = 82761276.1223\n",
      "Iteration 29: Cost Difference = 0.0733046233654\n",
      "Iteration 30: Cost Difference = 154743419.786\n",
      "Iteration 31: Cost Difference = 0.0732579231262\n",
      "Iteration 32: Cost Difference = 296298050.488\n",
      "Iteration 33: Cost Difference = 0.0731853246689\n",
      "Iteration 34: Cost Difference = 578150326.561\n",
      "Iteration 35: Cost Difference = 0.0730795860291\n",
      "Iteration 36: Cost Difference = 1143897402.03\n",
      "Iteration 37: Cost Difference = 0.0729217529297\n",
      "Iteration 38: Cost Difference = 2286002127.6\n",
      "Iteration 39: Cost Difference = 0.0726537704468\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF_recommender(4, verbose=True)\n",
    "nmf.fit(train_utility_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

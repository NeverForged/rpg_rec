{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so time to use Matrix Factorization. I'll be using Non-Negative Matrix Factorization (NMF). I'm a fan of Non-Negative Matrix Factorization for 2 reasons:\n",
    "1. There are no negative values, which prevents weird results. Since there is no 'thumbs down' other than not purchasing a product, I don;t want to have negative values spitting out negative results.\n",
    "2. I prefer the US matrix form, since it allows for manipulation with a K matrix... U is u x k, S is k x s, and K is a k x k matrix you can throw in... if K is I (identity) it has absolutly no effect, but you can maipulate results by tossing numbers on the off-diagonals (for example, in a boom recommender, you can find the group that pregnancy books are in, find the group that stillbirth books are in, and have it negativley influence result for pregnancy books if you're interested in stillbirth books, since that seems like a cruel thing to hit customers with)\n",
    "\n",
    "There is an issue however... I won't be able to use non-users to validate the way I did above; they need to get a vector at the same time as everyone else... so I need to 'knock out' values in my utility_matrix to fit back in later...but that means I need to grab that again, since I'm in a new notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# first load my data...\n",
    "ratings = pd.read_csv('../data/ratings.csv', delimiter='|', header=None, names=['user_id', 'system_id', 'ratings'])\n",
    "\n",
    "# get highest user_id & highest system_id\n",
    "highest_user_id = ratings.user_id.max()\n",
    "highest_system_id = ratings.system_id.max()\n",
    "\n",
    "# make a sparse matrix...\n",
    "utility_matrix = sparse.lil_matrix((highest_user_id + 1, highest_system_id + 1))\n",
    "# +1 to be able to use actual ids, as opposed to having to make consessions\n",
    "\n",
    "# of course, now I need to fill it with ratings...\n",
    "for _, row in ratings.iterrows():\n",
    "        utility_matrix[row.user_id, row.system_id] = row.ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to remove 20% of my data points and call it the *train_utility_matrix*.  Goal is to make a list of tuples of *user_id* and *system_id*, then set the values at those locations to 0 in a copy of the *utility_matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n",
      "14.0 0.0\n",
      "1.0 0.0\n",
      "4.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "train_utility_matrix = utility_matrix.copy()\n",
    "utility_dict = utility_matrix.todok(copy=False)\n",
    "lst = utility_dict.keys()\n",
    "shuffle(lst)\n",
    "cut = int(len(lst)*0.8)\n",
    "train = lst[:cut]\n",
    "hold_out = lst[cut:]\n",
    "\n",
    "# now remove hold_out\n",
    "for tup in hold_out:\n",
    "    train_utility_matrix[tup] = 0\n",
    "    \n",
    "for tup in hold_out[:5]:\n",
    "    print utility_matrix[tup], train_utility_matrix[tup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NMF module from [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) does not seem like [a good fit](https://stackoverflow.com/questions/33623144/how-can-i-make-recommendation-model-using-pythons-scikit-learn) as it does not seem to allow much modification of the cost function to account for recommendation systems.  So, I'll need to write my own.\n",
    "Luckily I did build an NMF class as part of my [Galvanize data science course](https://www.galvanize.com/seattle/data-science), so that's floating around my hard drive/github.\n",
    "But, I need to change my cost function to the following cost function (thank you [Matt Drury](https://github.com/madrury)):\n",
    "$$arg: min_{U,V,b^*,b'} \\sum_{i, j \\in \\kappa} (r_{ij} - \\mu - b_i^* - b_j' - u_{i:} \\cdot v_{:j})^2 + \\lambda_1(|u_{i:}|^2 + |v_{:j}|^2) + \\lambda_2((b_i^*)^2 + (b_j')^2) $$\n",
    "Where $r_{ij}$ is user i's rating of item j, $u_{i:}$ is the way user i interacts with our latent features, $v_{j:}$ is how item j is described in terms of our latent features, $b_i^*$ is how much user i deviates from the overall average, and $b_j'$ is how much item j deviates from the overall average, $\\mu$.  This gives me a rating function of:\n",
    "$$r_{ij} \\approx \\mu + b_i^* + b_j' + u_{i:} \\cdot v_{:j}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "class NMF_recommender(object):\n",
    "    '''\n",
    "    A Non-Negative Matrix Factorization recommender.\n",
    "    Parameters:\n",
    "        k - The number of latent features\n",
    "        max_iter - number of iterations before the Factorization cancels out\n",
    "        thresh - the threshold, how different the cost function needs to be in\n",
    "                 in order to kick out of the iterations.\n",
    "        l1 - lamba_1 in cost function\n",
    "        l2 - lamba_2 in cost function\n",
    "        verbose - set True to print out Cost Function during fitting\n",
    "            \n",
    "    Attributes:\n",
    "        k - number of latent features\n",
    "        iter - max_iter\n",
    "        thresh - threshold paramater\n",
    "        l1 - lamba_1\n",
    "        l2 - lamba_2\n",
    "    '''\n",
    "\n",
    "    def __init__(self, k, max_iter=100, thresh=0.0001, l1=0.1, l2=0.1, verbose=False):\n",
    "        '''\n",
    "        Initializer.  See class for details.\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.thresh = thresh\n",
    "        self.iter = max_iter\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Fit function for the recommender system.\n",
    "        Parameters:\n",
    "            X - the utility-matrix we are trying to fit to\n",
    "\n",
    "        Attributes:\n",
    "            V - utility matrix in array form\n",
    "            nonzero - a numpy array that is 1 where utility matrix is\n",
    "                      nonzero and 0 otherwise\n",
    "            b_star - how much users deviate from average\n",
    "            b_prime - how much items deviate from average\n",
    "            b_matrix - a matrix of b_stari - b_primej for all i,j\n",
    "            cost - the cost function for a recommender\n",
    "            W - User matrix\n",
    "            H - Item Matrix\n",
    "        '''\n",
    "        # turn utility matrix to an arry\n",
    "        self.V = X.toarray()\n",
    "        nonzero = np.where(self.V > 0,1 ,0)\n",
    "        k  = self.k\n",
    "        \n",
    "        # find mu...\n",
    "        self.mu = np.sum(self.V)/np.count_nonzero(self.V)\n",
    "        \n",
    "        # find b_star & b_prime\n",
    "        self.b_star = np.mean(self.V - self.mu*nonzero, axis=1)\n",
    "        self.b_prime = np.mean(self.V - self.mu*nonzero, axis=0)\n",
    "        \n",
    "        # make b_matrix...\n",
    "        # first, get a matrix of b_star as columns\n",
    "        self.b_matrix =  np.column_stack((self.b_star for a in xrange(self.b_prime.shape[0])))\n",
    "        # add to b_prime as rows...\n",
    "        self.b_matrix = self.b_matrix + np.row_stack((self.b_prime for a in xrange(self.b_star.shape[0])))\n",
    "       \n",
    "        \n",
    "        self.W = np.random.random_sample((self.V.shape[0], k))\n",
    "        self.H = np.ones((k, self.V.shape[1]))\n",
    "        if self.verbose:\n",
    "            print 'Getting cost...'\n",
    "        #cost function...\n",
    "        Q = self.V - self.mu - self.b_matrix\n",
    "        self.cost = (np.linalg.norm(Q - self.W.dot(self.H)) + \n",
    "                         self.l1*(np.linalg.norm(self.W) + np.linalg.norm(self.H)) +\n",
    "                         self.l2*(self.b_star.dot(self.b_star) + self.b_prime.dot(self.b_prime)))\n",
    "        if self.verbose:\n",
    "            print 'Cost starts at: {}'.format(self.cost)\n",
    "        n = 0\n",
    "        old_cost = self.cost + 2 * self.thresh\n",
    "        while (n < self.iter) and (abs(old_cost - self.cost) > self.thresh):\n",
    "            if n % 2 == 0:\n",
    "                self.H = np.linalg.lstsq(self.W, self.V)[0]\n",
    "                self.H[self.H < 0] = 0\n",
    "            else:\n",
    "                self.W = np.linalg.lstsq(self.H.T, self.V.T)[0].T\n",
    "                self.W[self.W < 0] = 0\n",
    "            old_cost = self.cost\n",
    "            self.cost = (np.linalg.norm(Q - self.W.dot(self.H)) + \n",
    "                         self.l1*(np.linalg.norm(self.W) + np.linalg.norm(self.H)) +\n",
    "                         self.l2*(self.b_star.dot(self.b_star) + self.b_prime.dot(self.b_prime)))\n",
    "            n +=1\n",
    "            if self.verbose:\n",
    "                print \"Iteration {}: Cost Difference = {}\".format(n, abs(old_cost - self.cost))\n",
    "        return self.W, self.H\n",
    "    \n",
    "    def predict(self):\n",
    "        '''\n",
    "        Get values for items.                \n",
    "        Attributes:\n",
    "            ratings - The returned ratings\n",
    "        '''\n",
    "        self.ratings = self.mu + self.b_matrix + self.W.dot(self.H)\n",
    "        return self.ratings\n",
    "\n",
    "    def predict_cold(self, v):\n",
    "        '''\n",
    "         Fit function for the recommender system.\n",
    "        Parameters:\n",
    "            v - a list of tuples describing how user rated items,\n",
    "                format [(item_1, rating_1), (item_2, rating_2), ..., (item_n, raing_n)]\n",
    "\n",
    "        Attributes:\n",
    "            ratings - The returned ratings for all the included users\n",
    "        '''\n",
    "        # make sure we have ratings\n",
    "        try:\n",
    "            ratings = self.ratings\n",
    "        except:\n",
    "            ratings = self.predict()\n",
    "        pass\n",
    "\n",
    "    def get_rmse(self, X_full):\n",
    "        '''\n",
    "        Assumes a training matrix with missing values was used, checks the values that are in\n",
    "        X_full but not in self.V and calculates the RMSE.\n",
    "        Parameters:\n",
    "            X_full - the utility-matrix that vaules were removed from to get X in our fit\n",
    "\n",
    "        Attributes:\n",
    "            Xf - the full utility matric\n",
    "            rmse - root mean squared error\n",
    "        '''\n",
    "         # make sure we have ratings\n",
    "        ratings = self.predict()\n",
    "        self.Xf = X_full.toarray()\n",
    "        X_1 = np.where(self.Xf > 0, 1, 0)\n",
    "        X_2 = np.where(self.V == 0, 0, 1)\n",
    "        X_check = X_1 - X_2\n",
    "        X_check[X_check <= 0] = 0\n",
    "        self.rmse = sqrt(np.sum((self.Xf[X_check==1] - self.ratings[X_check==1])**2)/float(np.count_nonzero(X_check)))\n",
    "        return self.rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.6284792019 for k=4, l1=0.1, l2=0.1\n",
      "RMSE = 1.62845696799 for k=4, l1=0.1, l2=0.2\n",
      "RMSE = 1.62952084154 for k=4, l1=0.1, l2=0.3\n",
      "RMSE = 1.62861705405 for k=4, l1=0.1, l2=0.4\n",
      "RMSE = 1.62844845223 for k=4, l1=0.1, l2=0.5\n",
      "RMSE = 1.62845195909 for k=4, l1=0.1, l2=0.6\n",
      "RMSE = 1.62848109632 for k=4, l1=0.1, l2=0.7\n",
      "RMSE = 1.62847024504 for k=4, l1=0.1, l2=0.8\n",
      "RMSE = 1.62848471235 for k=4, l1=0.1, l2=0.9\n",
      "RMSE = 1.63127253272 for k=4, l1=0.1, l2=1.0\n",
      "RMSE = 1.62844057969 for k=4, l1=0.2, l2=0.1\n",
      "RMSE = 1.62848052097 for k=4, l1=0.2, l2=0.2\n",
      "RMSE = 1.62960101803 for k=4, l1=0.2, l2=0.3\n",
      "RMSE = 1.62996142999 for k=4, l1=0.2, l2=0.4\n",
      "RMSE = 1.62963999932 for k=4, l1=0.2, l2=0.5\n",
      "RMSE = 1.62844261406 for k=4, l1=0.2, l2=0.6\n",
      "RMSE = 1.6284789371 for k=4, l1=0.2, l2=0.7\n",
      "RMSE = 1.62847667829 for k=4, l1=0.2, l2=0.8\n",
      "RMSE = 1.62846089332 for k=4, l1=0.2, l2=0.9\n",
      "RMSE = 1.62847389739 for k=4, l1=0.2, l2=1.0\n",
      "RMSE = 1.62844232094 for k=4, l1=0.3, l2=0.1\n",
      "RMSE = 1.63144135683 for k=4, l1=0.3, l2=0.2\n",
      "RMSE = 1.62843458724 for k=4, l1=0.3, l2=0.3\n",
      "RMSE = 1.63029812427 for k=4, l1=0.3, l2=0.4\n",
      "RMSE = 1.62848174608 for k=4, l1=0.3, l2=0.5\n",
      "RMSE = 1.62847519922 for k=4, l1=0.3, l2=0.6\n",
      "RMSE = 1.62847199729 for k=4, l1=0.3, l2=0.7\n",
      "RMSE = 1.62847989959 for k=4, l1=0.3, l2=0.8\n",
      "RMSE = 1.62847853896 for k=4, l1=0.3, l2=0.9\n",
      "RMSE = 1.62983743979 for k=4, l1=0.3, l2=1.0\n",
      "RMSE = 1.62905755925 for k=4, l1=0.4, l2=0.1\n",
      "RMSE = 1.62848396931 for k=4, l1=0.4, l2=0.2\n",
      "RMSE = 1.62843871207 for k=4, l1=0.4, l2=0.3\n",
      "RMSE = 1.62843114062 for k=4, l1=0.4, l2=0.4\n",
      "RMSE = 1.62844647032 for k=4, l1=0.4, l2=0.5\n",
      "RMSE = 1.62845938262 for k=4, l1=0.4, l2=0.6\n",
      "RMSE = 1.62947991071 for k=4, l1=0.4, l2=0.7\n",
      "RMSE = 1.62952977897 for k=4, l1=0.4, l2=0.8\n",
      "RMSE = 1.6284900608 for k=4, l1=0.4, l2=0.9\n",
      "RMSE = 1.62849083051 for k=4, l1=0.4, l2=1.0\n",
      "RMSE = 1.62844549018 for k=4, l1=0.5, l2=0.1\n",
      "RMSE = 1.6311866734 for k=4, l1=0.5, l2=0.2\n",
      "RMSE = 1.6284394906 for k=4, l1=0.5, l2=0.3\n",
      "RMSE = 1.62848195595 for k=4, l1=0.5, l2=0.4\n",
      "RMSE = 1.6284400662 for k=4, l1=0.5, l2=0.5\n",
      "RMSE = 1.62848171201 for k=4, l1=0.5, l2=0.6\n",
      "RMSE = 1.62842898902 for k=4, l1=0.5, l2=0.7\n",
      "RMSE = 1.6284725841 for k=4, l1=0.5, l2=0.8\n",
      "RMSE = 1.62846774677 for k=4, l1=0.5, l2=0.9\n",
      "RMSE = 1.62846746722 for k=4, l1=0.5, l2=1.0\n",
      "RMSE = 1.62844457631 for k=4, l1=0.6, l2=0.1\n",
      "RMSE = 1.62849589239 for k=4, l1=0.6, l2=0.2\n",
      "RMSE = 1.62848992966 for k=4, l1=0.6, l2=0.3\n",
      "RMSE = 1.62841929006 for k=4, l1=0.6, l2=0.4\n",
      "RMSE = 1.62981294812 for k=4, l1=0.6, l2=0.5\n",
      "RMSE = 1.62841876436 for k=4, l1=0.6, l2=0.6\n",
      "RMSE = 1.62844802748 for k=4, l1=0.6, l2=0.7\n",
      "RMSE = 1.62844577636 for k=4, l1=0.6, l2=0.8\n",
      "RMSE = 1.63188117364 for k=4, l1=0.6, l2=0.9\n",
      "RMSE = 1.62846948367 for k=4, l1=0.6, l2=1.0\n",
      "RMSE = 1.62846918256 for k=4, l1=0.7, l2=0.1\n",
      "RMSE = 1.63324009798 for k=4, l1=0.7, l2=0.2\n",
      "RMSE = 1.62843072624 for k=4, l1=0.7, l2=0.3\n",
      "RMSE = 1.62846823896 for k=4, l1=0.7, l2=0.4\n",
      "RMSE = 1.63340229543 for k=4, l1=0.7, l2=0.5\n",
      "RMSE = 1.62962504506 for k=4, l1=0.7, l2=0.6\n",
      "RMSE = 1.62943915643 for k=4, l1=0.7, l2=0.7\n",
      "RMSE = 1.62844756328 for k=4, l1=0.7, l2=0.8\n",
      "RMSE = 1.63091122207 for k=4, l1=0.7, l2=0.9\n",
      "RMSE = 1.62964744536 for k=4, l1=0.7, l2=1.0\n",
      "RMSE = 1.63219524766 for k=4, l1=0.8, l2=0.1\n",
      "RMSE = 1.62845772552 for k=4, l1=0.8, l2=0.2\n",
      "RMSE = 1.62845572815 for k=4, l1=0.8, l2=0.3\n",
      "RMSE = 1.63112565456 for k=4, l1=0.8, l2=0.4\n",
      "RMSE = 1.62847766272 for k=4, l1=0.8, l2=0.5\n",
      "RMSE = 1.62847678969 for k=4, l1=0.8, l2=0.6\n",
      "RMSE = 1.6284356504 for k=4, l1=0.8, l2=0.7\n",
      "RMSE = 1.62846996715 for k=4, l1=0.8, l2=0.8\n",
      "RMSE = 1.62849126745 for k=4, l1=0.8, l2=0.9\n",
      "RMSE = 1.63165717855 for k=4, l1=0.8, l2=1.0\n",
      "RMSE = 1.63059763643 for k=4, l1=0.9, l2=0.1\n",
      "RMSE = 1.62845327196 for k=4, l1=0.9, l2=0.2\n",
      "RMSE = 1.63345568499 for k=4, l1=0.9, l2=0.3\n",
      "RMSE = 1.62848447529 for k=4, l1=0.9, l2=0.4\n",
      "RMSE = 1.62840856868 for k=4, l1=0.9, l2=0.5\n",
      "RMSE = 1.62862198427 for k=4, l1=0.9, l2=0.6\n",
      "RMSE = 1.62843756067 for k=4, l1=0.9, l2=0.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ea936042cb57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF_recommender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_utility_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_rmse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-720673011bf9>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mold_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\darin\\Anaconda2\\lib\\site-packages\\numpy\\linalg\\linalg.pyc\u001b[0m in \u001b[0;36mlstsq\u001b[1;34m(a, b, rcond)\u001b[0m\n\u001b[0;32m   1913\u001b[0m     \u001b[0mreal_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_linalgRealType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m     \u001b[0mbstar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m     \u001b[0mbstar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_rhs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbstar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fastCopyAndTranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbstar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbstar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_native_byte_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbstar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ks = [a for a in range(4,35,2)]\n",
    "ls = [0.1*a for a in range(1, 11, 1)]\n",
    "best_k = 0\n",
    "best_l1 = 0\n",
    "best_l2 = 0\n",
    "best_rmse = 9001  # it's over 9000! (never saw that show)\n",
    "for k in ks:\n",
    "    for l1 in ls:\n",
    "        for l2 in ls:\n",
    "            nmf = NMF_recommender(k=k, max_iter=24, thresh=0.001, l1=l1, l2=l2, verbose=False)\n",
    "            nmf.fit(train_utility_matrix)\n",
    "            rmse = nmf.get_rmse(utility_matrix)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_k = k\n",
    "                best_l1 = l1\n",
    "                best_l2 = l2\n",
    "            print('RMSE = {} for k={}, l1={}, l2={}'.format(rmse, k, l1, l2)) \n",
    "print()\n",
    "print('Best params are k={}, l1={}, l2={}'.format(best_k, best_l1, best_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

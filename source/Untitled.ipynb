{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "\n",
    "# create spark session\n",
    "# use local[7] on ec2 instance\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "          .master('local[4]')  \\\n",
    "          .appName('rpg_rec') \\\n",
    "          .getOrCreate() \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the ratings data\n",
    "df = spark.read.csv('../data/ratings.csv',\n",
    "                       header=False,\n",
    "                       sep='|',\n",
    "                       inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to rdd...\n",
    "data_rdd = df.rdd\n",
    "\n",
    "# tarin/test sets...\n",
    "training_RDD, validation_RDD, test_RDD = data_rdd.randomSplit([6, 2, 2])\n",
    "# training_RDD, test_RDD = data_rdd.randomSplit([7, 3])\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a recommender...\n",
    "# Parameters\n",
    "seed = 5L\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [a for a in xrange(4,30,2)]\n",
    "errors = [0 for a in ranks]\n",
    "err = 0\n",
    "tolerance = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.901505880985\n",
      "For rank 6 the RMSE is 0.84211614967\n",
      "error at errors with rank 8\n",
      "error at errors with rank 10\n",
      "error at errors with rank 12\n",
      "error at errors with rank 14\n",
      "error at predicions with rank 16\n",
      "error at errors with rank 18\n",
      "error at errors with rank 20\n",
      "error at errors with rank 22\n",
      "error at errors with rank 24\n",
      "error at errors with rank 26\n",
      "error at errors with rank 28\n",
      "The best model was trained with rank 6\n"
     ]
    }
   ],
   "source": [
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    last = ''\n",
    "    try:\n",
    "        last = 'model'\n",
    "        model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "        last = 'predicions'\n",
    "        predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "        last = 'rates & predicions'\n",
    "        rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "        last = 'errors'\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        errors[err] = error\n",
    "        err += 1\n",
    "        print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_rank = rank\n",
    "    except:\n",
    "        print 'error at {} with rank {}'.format(last, rank)\n",
    "\n",
    "print 'The best model was trained with rank %s' % best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((125213, 31), (1.0, 0.18715964942219884)),\n",
       " ((327227, 105), (1.0, 0.9991674961583612)),\n",
       " ((158755, 0), (2.0, 0.9009769803647689))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = data_rdd.randomSplit([7, 3], seed=0L)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 2.23686618525\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print 'For testing data the RMSE is %s' % (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((340380, 113), (1.0, -0.14438680609851456)),\n",
       " ((1811, 113), (1.0, 1.6106886265138605)),\n",
       " ((428735, 72), (1.0, 0.3867859856321298)),\n",
       " ((70083, 141), (4.0, 0.5893066692050223)),\n",
       " ((180289, 24), (1.0, 0.9525949638509973)),\n",
       " ((25064, 105), (1.0, 0.37817178898650666)),\n",
       " ((294251, 18), (1.0, 1.4180347217366158)),\n",
       " ((110899, 19), (1.0, -0.10075682933664337)),\n",
       " ((375340, 105), (1.0, 0.4547428648449171)),\n",
       " ((592892, 141), (1.0, 0.23472907686081446)),\n",
       " ((76393, 113), (2.0, 0.5539527336643408)),\n",
       " ((236911, 105), (1.0, 0.28169569828579627))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
